{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb9pUStUq6xf"
      },
      "source": [
        "<img src = \"https://drive.google.com/uc?export=view&id=1F0W_cKP20hdHzrBOxPSNMLfL6xqLx6et\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dLr_3BecMJ6"
      },
      "source": [
        "# **_Machine Learning_ con _Apache Spark_**\n",
        "---\n",
        "\n",
        "En este _notebook_ se busca familiarizar al estudiante con el entorno de ejecución de _Apache Spark_ y sus funciones básicas con ayuda de _PySpark_ su _driver_ oficial para el lenguaje de programación _Python_. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8elHIrqcdIF"
      },
      "source": [
        "# **0. Instalar _PySpark_**\n",
        "---\n",
        "\n",
        "_PySpark_ es una librería de _Python_ que permite el acceso al motor de _Apache Spark_ desarrollado en el lenguaje de programación _Scala_, que también permite utilizar _Spark_ con el lenguaje _Python_. Este puede ser fácilmente instalado utilizando el gestor de paquetes de _Python_  **`pip`**, como se muestra a continuación. Primero, instalamos y configuramos la variable de entorno de **_Java 8_**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3ntvQO-mLjtF"
      },
      "outputs": [],
      "source": [
        "# Instalamos el OpenJDK 8 con apt-get.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fQB-NxOfLl_v"
      },
      "outputs": [],
      "source": [
        "# Configuramos la variable de entorno de Java.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzn11VlR0FG5"
      },
      "source": [
        "Finalmente, utilizamos **`pip`** para instalar _PySpark_ y su librería auxiliar _findspark_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggcHB3m4a0EJ",
        "outputId": "285319ee-1862-40cf-c6bc-43b7f7050099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.4 MB 45 kB/s \n",
            "\u001b[K     |████████████████████████████████| 199 kB 45.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Instalamos los paquetes de PySpark.\n",
        "!pip install -q pyspark\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUjz10Vrd77u"
      },
      "source": [
        "# **1. Instalar dependencias**\n",
        "---\n",
        "Antes de comenzar con la herramienta, vamos a instalar los módulos de *Python* utilizados en esta guía, empezando por **`pyspark`**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KwGEBXM3Uzt0"
      },
      "outputs": [],
      "source": [
        "# Importamos pyspark\n",
        "import pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGybRJ1_VLlH"
      },
      "source": [
        "Además, utilizaremos algunas librerías básicas de análisis y visualización de datos como _Pandas_, _NumPy_ y _Matplotlib_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HCgi0ERUpTz7"
      },
      "outputs": [],
      "source": [
        "# Librerías básicas de análisis de datos.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUMP_2CPqwRY",
        "outputId": "7cf7631e-adef-441a-b76f-b480afcb28eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.15\n",
            "PySpark 3.3.1\n",
            "NumPy 1.21.6\n",
            "Pandas 1.3.5\n",
            "Matplotlib 3.2.2\n"
          ]
        }
      ],
      "source": [
        "# Versiones de las librerías usadas.\n",
        "!python --version\n",
        "print('PySpark', pyspark.__version__)\n",
        "print('NumPy', np.__version__)\n",
        "print('Pandas', pd.__version__)\n",
        "print('Matplotlib', mpl.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39m9YIg5V3E0"
      },
      "source": [
        "Esta actividad se realizó con las siguientes versiones:\n",
        "*  *Python*: 3.7.10\n",
        "*  *PySpark*:  3.1.2\n",
        "*  *NumPy*:  1.19.5\n",
        "*  *Pandas*: 1.1.5\n",
        "*  *Matplotlib*:  3.2.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URNa7Zd4f2aZ"
      },
      "source": [
        "# **2. Operaciones básicas con _PySpark_**\n",
        "---\n",
        "Para comenzar a realizar operaciones con _Apache Spark_ es necesario declarar y almacenar el contexto de *Spark* (objeto **`pyspark.SparkContext`**), el cual es el objeto fundamental que permite la comunicación con el _cluster_. \n",
        "> **Nota**: solo puede existir un objeto contexto por máquina virtual, asegúrese de no volver a declarar la variable o de llamar el constructor **`SparkContext`**. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zW6C6DjLbDXz"
      },
      "outputs": [],
      "source": [
        "# Declaramos el contexto de Apache Spark y lo almacenamos en la variable 'sc'.\n",
        "sc = pyspark.SparkContext()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP0x0mm54242"
      },
      "source": [
        "A diferencia del taller de _Apache Spark_ con _DataBricks_, en un entorno como _Google Colaboratory_ es necesario definir explícitamente objetos como el contexto SQL (**`SQLContext`**). Para realizar esto, vamos a importar los objetos del módulo **`pyspark.sql`**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UH0mY28SZgFI"
      },
      "outputs": [],
      "source": [
        "# Contexto de Spark para operaciones SQL y en DataFrame.\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "# Objeto fila de una tabla SQL.\n",
        "from pyspark.sql import Row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce5RAq40ZjLv",
        "outputId": "df66ad84-cc44-49b9-debe-368b3317b205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Creamos el objeto SQLContext.\n",
        "sqlContext = SQLContext(sc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRuX_F-b3WaU"
      },
      "source": [
        "En esta ocasión, para crear un _DataFrame_ de _Spark_ vamos a declarar un objeto resistente a fallos **RDD** (del inglés _resilient distributed dataset_).Para crear un RDD se utiliza el método **`parallelize`** del objeto **`SparkContext`**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xb4hkyOPbxNm"
      },
      "outputs": [],
      "source": [
        "# Construimos un RDD a partir de una lista de valores.\n",
        "nums = sc.parallelize([1, 2, 3, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV0vkIgi659R"
      },
      "source": [
        "A partir de este objeto podemos realizar operaciones como las descritas en la guía anterior. Por ejemplo, podemos tomar los primeros $n$ valores de un RDD con el método **`take`**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsB3Krxdb7AV",
        "outputId": "836e2f66-25b4-4b60-bb3b-35f73d76183d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Tomamos los primeros 3 valores.\n",
        "nums.take(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUbsaqQC_Upk"
      },
      "source": [
        "También podemos realizar transformaciones como _map_, _filter_, entre otras. Por ejemplo, podemos realizar una operación de _mapeo_ de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7gUyYOkeJ9hu"
      },
      "outputs": [],
      "source": [
        "# Realizando una transformación de mapeo básica en un RDD.\n",
        "squared = nums.map(lambda x: x * x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG591SG7LAlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47cc2680-4879-4fb1-f3af-0a4379560f07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "squared.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD97VC9659sB"
      },
      "source": [
        "Aunque los RDD son estructuras de datos robustas y flexibles, manejar los datos en _DataFrames_ resulta más conveniente y sencillo en muchos casos. Vamos a crear un RDD y construir un objeto _DataFrame_ con ayuda del objeto de contexto SQL (_SQLContext_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ejTGYFUWbMIu"
      },
      "outputs": [],
      "source": [
        "# Creamos una lista de tuplas. Estas serán interpretadas como clave-valor.\n",
        "lista_p = [(\"John\", 20), (\"Camila\", 22), (\"Andres\", 25), (\"Nancy\", 18)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KPFMeHtfbgsQ"
      },
      "outputs": [],
      "source": [
        "# Creamos un RDD a partir de la lista de tuplas anterior.\n",
        "ppl_rdd = sc.parallelize(lista_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhKUQfrWA46G"
      },
      "source": [
        "Ahora, vamos a crear el esquema de la tabla, utilizando los nombre **`name`** y **`age`** y utilizando el objeto **`pyspark.sql.Row`** para asignar cada fila de la tabla a construir:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bAjHS9n6cia1"
      },
      "outputs": [],
      "source": [
        "# Creamos el esquema con ayuda del objeto Row.\n",
        "ppl = ppl_rdd.map(lambda x: Row(name = x[0],  # Nombre de la persona.\n",
        "                                age= int(x[1]) )) # Edad de la persona."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoZwxIDhBWgv"
      },
      "source": [
        "Finalmente, podemos utilizar el constructor **`sqlContext.createDataFrame`** y utilizar como entrada el RDD construido previamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9e9vQpBxdQGn"
      },
      "outputs": [],
      "source": [
        "# Creamos un DataFrame a partir del esquema anterior.\n",
        "DF_ppl = sqlContext.createDataFrame(ppl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlkMObmbBiN5"
      },
      "source": [
        "Ahora, podemos realizar operaciones sobre este _DataFrame_, como imprimir su esquema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "04Pryp9cdkJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40639f1f-1b9a-475b-8ffb-dfb515786a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Imprimimos el esquema del DataFrame para comprobar su correcto funcionamiento.\n",
        "DF_ppl.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QFZ1TcmB00B"
      },
      "source": [
        "Si intentamos imprimir el _DataFrame_ como en el taller de _Databricks_ nos encontramos con una representación más simple. Para esto, podemos recurrir a la simple representación posible con la función **`show`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Yx2fVzf4dzzp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "192b244e-7d99-48c5-807e-53c3b7b809f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[name: string, age: bigint]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Intentamos generar la representación del DataFrame.\n",
        "display(DF_ppl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "r8IeRiu9C92G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851d39a7-31d6-44cd-df4f-f80f85559a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|  name|age|\n",
            "+------+---+\n",
            "|  John| 20|\n",
            "|Camila| 22|\n",
            "|Andres| 25|\n",
            "| Nancy| 18|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Imprimimos una versión simplificada del DataFrame.\n",
        "DF_ppl.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3LtUHUUCb8E"
      },
      "source": [
        "Las características de visualización son propias de la plataforma _Databricks_. Si queremos realizar este tipo de operaciones, podemos utilizar el método **`toPandas`** y utilizar las utilidades de visualización de esta librería o de similares como _Seaborn_ y _Matplotlib_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qe5cN7d7CbLu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "64a70054-00dd-4f3b-d1be-66c2adb2025e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age\n",
              "name       \n",
              "John     20\n",
              "Camila   22\n",
              "Andres   25\n",
              "Nancy    18"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b92021e-a21b-4d75-a82e-65a96efe7888\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>John</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Camila</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Andres</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nancy</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b92021e-a21b-4d75-a82e-65a96efe7888')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b92021e-a21b-4d75-a82e-65a96efe7888 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b92021e-a21b-4d75-a82e-65a96efe7888');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Convertimos el DataFrame de Spark en un DataFrame de Pandas.\n",
        "pd_df = DF_ppl.toPandas().set_index('name')\n",
        "pd_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5vhqDVPDW0o"
      },
      "source": [
        "Lo visualizamos con las funciones del módulo **`plot`** de _Pandas_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ooGitpKrDdf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "68e828b0-1f96-4cd9-e4f0-9266ccf81870"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Utilizamos las utilidades de visualización de Pandas.\n",
        "pd_df.plot.bar();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp4Q17CNiRDw"
      },
      "source": [
        "# **3. _Machine Learning_ automático con _Apache Spark_**\n",
        "---\n",
        "\n",
        "En esta sección realizaremos un ejemplo de aplicación de problemas de aprendizaje automático o _machine learning_ en un contexto _Big Data_ utilizando _Apache Spark_ y sus funcionalidades para el desarrollo y evaluación de modelos.\n",
        "\n",
        "> **Nota**: esta sección pretende ejemplificar la aplicación de los conceptos discutidos en el Módulo 2, Introducción a _Machine Learning_ con _Python_ con la tecnología presentada en este módulo y es de **carácter opcional**. Si usted no cursó el módulo mencionado o desea realizar un repaso de las ideas discutidas puede consultar los enlaces ubicados en la sección de recursos adicionales para adquirir una noción básica de lo discutido en este material. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oUIVZHXxQPE"
      },
      "source": [
        "## **3.1. Clasificación con _Apache Spark_**\n",
        "---\n",
        "En este primer ejemplo vamos a utilizar el _dataset_ [_Breast Cancer Wisconsin_](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/) del [repositorio de la Universidad de _California, Irvine_](https://archive.ics.uci.edu/ml/datasets.php) que corresponde a un conjunto de datos utilizado en la clasificación de tumores de cáncer de seno y que cuenta con las siguientes columnas, separadas por comas:\n",
        "\n",
        "  | Variable |  Definición  |            Valores |\n",
        "  |---|-----------------|----------------------|\n",
        "  | sample_code |Código numérico de muestreo |            Índice |\n",
        "  | clump_thickness | Grosor de la masa.|               Número entero (1-10) |\n",
        "  | unif_cell_size | Uniformidad del tamaño de la célula.|       Número entero (1-10)|\n",
        "  | unif_cell_shape |Uniformidad de la forma de la célula.|      Número entero (1-10)|\n",
        "  | marg_adhesion | Adhesión marginal.|             Número entero (1-10)|\n",
        "  | sgl_epith_cell_size | Tamaño de célula epitelial individual. |   Número entero (1-10)|\n",
        "  | bare_nuclei | Núcleos desnudos. |                  Número entero (1-10)|\n",
        "  | bland_chromatin |Cromatina blanda. |              Número entero (1-10)|\n",
        "  | normal_nucleoli | Nucleólos normales.  |             Número entero (1-10)|\n",
        "  | mitoses| Mitosis.  |                     Número entero (1-10)|\n",
        "  | class | Clase o etiqueta del diagnóstico.       |                  (2 para benigno, 4 for maligno)\n",
        "\n",
        "\n",
        "  Empezaremos por descargar el _dataset_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jaqj5DDYkMRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1179e2-cca4-43aa-9191-67fd9846d995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-28 21:56:51--  https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19889 (19K) [application/x-httpd-php]\n",
            "Saving to: ‘breast-cancer-wisconsin.data’\n",
            "\n",
            "breast-cancer-wisco 100%[===================>]  19.42K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-11-28 21:56:52 (307 KB/s) - ‘breast-cancer-wisconsin.data’ saved [19889/19889]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Descargamos el archivo de dataset del repositorio de la UCI.\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLtkfkwDhN12"
      },
      "source": [
        "Debemos cargar el archivo de nuestro sistema de archivos local al sistema de archivos de _Apache Spark_. Para ello debemos agregarlo como un recurso de _Spark_. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "92e2_OkGmG1W"
      },
      "outputs": [],
      "source": [
        "# Agregamos el archivo de datos como un recurso de Spark\n",
        "sc.addFile(\"breast-cancer-wisconsin.data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6lgx9w7lFWg"
      },
      "source": [
        "Ahora usamos la utilidad **`SparkFiles`** para obtener la ruta absoluta del archivo y cargamos el _dataset_ en un _DataFrame_ con la función **`sqlContext.read.sql`**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yJp90G_Ph_YR"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkFiles\n",
        "\n",
        "# Leemos el archivo de datos con ayuda del sqlcontext\n",
        "# sqlContext.read.csv(\"breast-cancer-wisconsin.data\", header=False, inferSchema=True)\n",
        "df_cancer = sqlContext.read.csv(SparkFiles.get(\"breast-cancer-wisconsin.data\"), \n",
        "                                header=False, \n",
        "                                inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oIMNs9qRjVDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a1c251-59ac-41c0-9038-107dd12e749e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- _c1: integer (nullable = true)\n",
            " |-- _c2: integer (nullable = true)\n",
            " |-- _c3: integer (nullable = true)\n",
            " |-- _c4: integer (nullable = true)\n",
            " |-- _c5: integer (nullable = true)\n",
            " |-- _c6: string (nullable = true)\n",
            " |-- _c7: integer (nullable = true)\n",
            " |-- _c8: integer (nullable = true)\n",
            " |-- _c9: integer (nullable = true)\n",
            " |-- _c10: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Verificamos los tipos inferidos imprimiendo el esquema.\n",
        "df_cancer.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rX7399Z1Hkb"
      },
      "source": [
        "Como puede notar, la variable ubicada en la sexta columna (**`bare_nuclei`**) fue identificada como una cadena de caracteres. Empecemos por observar los valores únicos de la columna con el método **`distinct`**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kwwP6INFdpbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ca1a8a-5d73-4c97-8a9a-90b249c8c238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|_c6|\n",
            "+---+\n",
            "|  7|\n",
            "|  3|\n",
            "|  8|\n",
            "|  5|\n",
            "|  6|\n",
            "|  9|\n",
            "|  1|\n",
            "| 10|\n",
            "|  4|\n",
            "|  ?|\n",
            "|  2|\n",
            "+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_cancer.select(\"_c6\").distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTbVBrut9jmp"
      },
      "source": [
        "Para realizar una limpieza apropiada de los datos, debemos filtrar los valores faltantes (expresados con signo de interrogación **`?`**) y dejar únicamente las columnas con valores válidos. Podemos hacer esto con el método **`where`** del objeto **`DataFrame`**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7AQ4-OLd9jC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0082d1e-d213-4ff3-eed5-548a9cb66308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|_c6|\n",
            "+---+\n",
            "|  7|\n",
            "|  3|\n",
            "|  8|\n",
            "|  5|\n",
            "|  6|\n",
            "|  9|\n",
            "|  1|\n",
            "| 10|\n",
            "|  4|\n",
            "|  2|\n",
            "+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_cancer = df_cancer.where(df_cancer[\"_c6\"] != \"?\")\n",
        "\n",
        "df_cancer.select(\"_c6\").distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zpvZCZI-FQj"
      },
      "source": [
        "Ahora, convertimos la columna del tipo de dato **`string`** al tipo **`integer`** con la función **`withColumn`** para reasignar la columna y la función **`cast`** para realizar la conversión de tipos. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_TIRoNpOAWPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25863496-260b-4aab-95b0-15d516a55997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+---+---+---+---+---+---+---+---+----+\n",
            "|    _c0|_c1|_c2|_c3|_c4|_c5|_c6|_c7|_c8|_c9|_c10|\n",
            "+-------+---+---+---+---+---+---+---+---+---+----+\n",
            "|1000025|  5|  1|  1|  1|  2|  1|  3|  1|  1|   2|\n",
            "|1002945|  5|  4|  4|  5|  7| 10|  3|  2|  1|   2|\n",
            "|1015425|  3|  1|  1|  1|  2|  2|  3|  1|  1|   2|\n",
            "|1016277|  6|  8|  8|  1|  3|  4|  3|  7|  1|   2|\n",
            "|1017023|  4|  1|  1|  3|  2|  1|  3|  1|  1|   2|\n",
            "|1017122|  8| 10| 10|  8|  7| 10|  9|  7|  1|   4|\n",
            "|1018099|  1|  1|  1|  1|  2| 10|  3|  1|  1|   2|\n",
            "|1018561|  2|  1|  2|  1|  2|  1|  3|  1|  1|   2|\n",
            "|1033078|  2|  1|  1|  1|  2|  1|  1|  1|  5|   2|\n",
            "|1033078|  4|  2|  1|  1|  2|  1|  2|  1|  1|   2|\n",
            "+-------+---+---+---+---+---+---+---+---+---+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_cancer = df_cancer.withColumn(\"_c6\", df_cancer[\"_c6\"].cast(\"int\"))\n",
        "df_cancer.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LUn9j_e7AxO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b347380e-5325-4e79-a28d-958b57a70dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- _c1: integer (nullable = true)\n",
            " |-- _c2: integer (nullable = true)\n",
            " |-- _c3: integer (nullable = true)\n",
            " |-- _c4: integer (nullable = true)\n",
            " |-- _c5: integer (nullable = true)\n",
            " |-- _c6: integer (nullable = true)\n",
            " |-- _c7: integer (nullable = true)\n",
            " |-- _c8: integer (nullable = true)\n",
            " |-- _c9: integer (nullable = true)\n",
            " |-- _c10: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_cancer.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fKW1sMHkmeT"
      },
      "source": [
        "Las columnas han sido cargadas con nombres automáticos sin relación con las variables originales. Podemos renombrarlas con el método **`withColumnRenamed`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kUvfprhUkxNc"
      },
      "outputs": [],
      "source": [
        "# Lista de nombres de las variables.\n",
        "target_names = [\"sample_code\", \n",
        "                \"clump_thickness\", \n",
        "                \"unif_cell_size\", \n",
        "                \"unif_cell_shape\", \n",
        "                \"marg_adhesion\", \n",
        "                \"sgl_epith_cell_size\",\n",
        "                \"bare_nuclei\", \n",
        "                \"bland_chromatin\", \n",
        "                \"normal_nucleoli\", \n",
        "                \"mitoses\", \n",
        "                \"class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "EbNK0d96lyMz"
      },
      "outputs": [],
      "source": [
        "# Cambiamos los nombres a las columnas\n",
        "for i in range(0, len(target_names)):\n",
        "  df_cancer = df_cancer.withColumnRenamed(f\"_c{i}\", target_names[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lGQuVdGzmXjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24fbee83-6417-4e43-81de-df69ef4aeade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sample_code: integer (nullable = true)\n",
            " |-- clump_thickness: integer (nullable = true)\n",
            " |-- unif_cell_size: integer (nullable = true)\n",
            " |-- unif_cell_shape: integer (nullable = true)\n",
            " |-- marg_adhesion: integer (nullable = true)\n",
            " |-- sgl_epith_cell_size: integer (nullable = true)\n",
            " |-- bare_nuclei: integer (nullable = true)\n",
            " |-- bland_chromatin: integer (nullable = true)\n",
            " |-- normal_nucleoli: integer (nullable = true)\n",
            " |-- mitoses: integer (nullable = true)\n",
            " |-- class: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Imprimimos el esquema para confirmar el cambio.\n",
        "df_cancer.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gOE0UW3bnvjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad70700-0e9b-4afe-e056-a94940d2cd45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------------+--------------+---------------+-------------+-------------------+-----------+---------------+---------------+-------+-----+\n",
            "|sample_code|clump_thickness|unif_cell_size|unif_cell_shape|marg_adhesion|sgl_epith_cell_size|bare_nuclei|bland_chromatin|normal_nucleoli|mitoses|class|\n",
            "+-----------+---------------+--------------+---------------+-------------+-------------------+-----------+---------------+---------------+-------+-----+\n",
            "|1000025    |5              |1             |1              |1            |2                  |1          |3              |1              |1      |2    |\n",
            "|1002945    |5              |4             |4              |5            |7                  |10         |3              |2              |1      |2    |\n",
            "|1015425    |3              |1             |1              |1            |2                  |2          |3              |1              |1      |2    |\n",
            "|1016277    |6              |8             |8              |1            |3                  |4          |3              |7              |1      |2    |\n",
            "|1017023    |4              |1             |1              |3            |2                  |1          |3              |1              |1      |2    |\n",
            "+-----------+---------------+--------------+---------------+-------------+-------------------+-----------+---------------+---------------+-------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mostramos la tabla con los nuevos nombres de variables.\n",
        "df_cancer.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ewghLe7oR71"
      },
      "source": [
        "Para verificar que las clases están balanceadas, agruparemos y contaremos los datos en cada grupo, representado por la variable **`class`**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XlVHchteoh6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475b0d92-1dc2-444c-f4e0-5f20acad101a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|class|count|\n",
            "+-----+-----+\n",
            "|    4|  239|\n",
            "|    2|  444|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_cancer.groupBy(\"class\").count().sort(\"count\", ascending=True).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmag7zycpEW6"
      },
      "source": [
        "Podemos realizar un análisis exploratorio de los datos por medios de las medidas estadísticas básicas tales como:\n",
        "* Conteo (**`count`**).\n",
        "* Media aritmética (**`mean`**).\n",
        "* Desviación Estándar (**`stddev`**).\n",
        "* Mínimo (**`min`**).\n",
        "* Máximo (**`max`**).\n",
        "\n",
        "Para esto, utilizamos la función **`describe`**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1vq5-FCRpDvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45f4bb1e-d06f-4c32-9b87-d998f9699e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+------------------+------------------+-----------------+-------------------+------------------+-----------------+------------------+------------------+------------------+\n",
            "|summary|       sample_code|   clump_thickness|    unif_cell_size|   unif_cell_shape|    marg_adhesion|sgl_epith_cell_size|       bare_nuclei|  bland_chromatin|   normal_nucleoli|           mitoses|             class|\n",
            "+-------+------------------+------------------+------------------+------------------+-----------------+-------------------+------------------+-----------------+------------------+------------------+------------------+\n",
            "|  count|               683|               683|               683|               683|              683|                683|               683|              683|               683|               683|               683|\n",
            "|   mean|1076720.2269399706|  4.44216691068814| 3.150805270863836|3.2152269399707176|2.830161054172767|  3.234260614934114|3.5446559297218156|3.445095168374817| 2.869692532942899| 1.603221083455344|2.6998535871156664|\n",
            "| stddev| 620644.0476548711|2.8207613188371266|3.0651448557860426|2.9885808183250244|2.864562190446995| 2.2230854564417952| 3.643857160492912|2.449696572512872|3.0526664070473566|1.7326741463370268|0.9545922233303009|\n",
            "|    min|             63375|                 1|                 1|                 1|                1|                  1|                 1|                1|                 1|                 1|                 2|\n",
            "|    max|          13454352|                10|                10|                10|               10|                 10|                10|               10|                10|                10|                 4|\n",
            "+-------+------------------+------------------+------------------+------------------+-----------------+-------------------+------------------+-----------------+------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_cancer.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ukWwEqpsphvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3f7457-bb34-4241-f51b-bcf167c91854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+\n",
            "|summary|   clump_thickness|    unif_cell_size|\n",
            "+-------+------------------+------------------+\n",
            "|  count|               683|               683|\n",
            "|   mean|  4.44216691068814| 3.150805270863836|\n",
            "| stddev|2.8207613188371266|3.0651448557860426|\n",
            "|    min|                 1|                 1|\n",
            "|    max|                10|                10|\n",
            "+-------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Para obtener la descripción de una o varias columnas puede colocar\n",
        "# el nombre de las columnas dentro del método describe.\n",
        "df_cancer.describe(\"clump_thickness\", \"unif_cell_size\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNAqxb7msWvM"
      },
      "source": [
        "Podemos realizar tablas de contingencia con el método **`crosstab`**. Esta permite comparar la concentración de valores en dos columnas y puede mostrarnos interesantes relaciones. Exploremos la relación entre la variable **`unif_cell_size`** y el vector de etiquetas **`class`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JARh0FJmsXIT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "38fc51f9-eff2-4cf7-d40d-fc81317c7b67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  unif_cell_size_class    2   4\n",
              "0                    1  369   4\n",
              "1                   10    0  67\n",
              "2                    2   37   8\n",
              "3                    3   27  25\n",
              "4                    4    8  30\n",
              "5                    5    0  30\n",
              "6                    6    0  25\n",
              "7                    7    1  18\n",
              "8                    8    1  27\n",
              "9                    9    1   5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5eeb9e1-2950-4ec4-9c58-b721d312af06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unif_cell_size_class</th>\n",
              "      <th>2</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>369</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5eeb9e1-2950-4ec4-9c58-b721d312af06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5eeb9e1-2950-4ec4-9c58-b721d312af06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5eeb9e1-2950-4ec4-9c58-b721d312af06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "df_cancer.crosstab(\"unif_cell_size\", \"class\").sort(\"unif_cell_size_class\", ascending=True).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTYJDMNEBYuj"
      },
      "source": [
        "Ahora, procedemos a realizar el preprocesamiento, y en particular, la selección de las columnas que conformarán las características. En este caso, omitiremos el índice y la variable objetivo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "kdreXwztBYSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b37a83-7a2c-4044-ae99-9633cd949c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['clump_thickness', 'unif_cell_size', 'unif_cell_shape', 'marg_adhesion', 'sgl_epith_cell_size', 'bare_nuclei', 'bland_chromatin', 'normal_nucleoli', 'mitoses']\n"
          ]
        }
      ],
      "source": [
        "feature_cols = df_cancer.columns[1:10]\n",
        "print(feature_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z78mgBXjr9wq"
      },
      "source": [
        "Podemos utilizar la función **`pyspark.ml.feature.VectorAssembler`** para convertir dichas columnas en una única variable en formato de vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DYPe9zjs9FmO"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols = feature_cols, \n",
        "                            outputCol = \"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TYfrxi8-CZo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c379ca5-dce4-4b94-db16-ea23fcdc7755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[5.0,1.0,1.0,1.0,...|\n",
            "|[5.0,4.0,4.0,5.0,...|\n",
            "|[3.0,1.0,1.0,1.0,...|\n",
            "|[6.0,8.0,8.0,1.0,...|\n",
            "|[4.0,1.0,1.0,3.0,...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = assembler.transform(df_cancer)\n",
        "df.select('features').show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKpeDRhjCp-A"
      },
      "source": [
        "Ahora, vamos a filtrar los datos y conservar únicamente las columnas **`class`** y **`features`** realizando una selección."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PJrvg1ObCaQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bcf4b3-28fa-4a54-da00-23244ae6f0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|class|            features|\n",
            "+-----+--------------------+\n",
            "|    2|[5.0,1.0,1.0,1.0,...|\n",
            "|    2|[5.0,4.0,4.0,5.0,...|\n",
            "|    2|[3.0,1.0,1.0,1.0,...|\n",
            "|    2|[6.0,8.0,8.0,1.0,...|\n",
            "|    2|[4.0,1.0,1.0,3.0,...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = df.select(\"class\", \"features\")\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q-AyUEEDGvI"
      },
      "source": [
        "La clase contiene únicamente los valores $2$ y $4$, pero queremos que correspondan a los valores $0$ y $1$. Esta codificación es posible utilizando la clase **`StringIndexer`** del módulo **`pyspark.ml.feature`**. Esta clase se comporta como un transformador (como los disponibles en la librería de _machine learning_ de _Python_: _Scikit-Learn_) y debe pasar por los métodos **`fit`** y **`transform`**, usando el _DataFrame_ como argumento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QwnalPCkC-ah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c2883c-10ec-4707-82ee-52d30edc5eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|[5.0,1.0,1.0,1.0,...|\n",
            "|  0.0|[5.0,4.0,4.0,5.0,...|\n",
            "|  0.0|[3.0,1.0,1.0,1.0,...|\n",
            "|  0.0|[6.0,8.0,8.0,1.0,...|\n",
            "|  0.0|[4.0,1.0,1.0,3.0,...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
        "indexed = indexer.fit(df)\n",
        "df = indexed.transform(df).select('label', 'features')\n",
        "\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFML20ZkDqHm"
      },
      "source": [
        "Ahora, utilizaremos el método **`sampleBy`** del objeto **`DataFrame`** para realizar una partición estratificada del conjunto en subconjuntos de entrenamiento (**`train`**) y pruebas (**`test`**) con una proporción de $70\\%-30\\%$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "vkWAdNNrDpmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe942f9-986d-465a-bc72-f2bf85fb5c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|[5.0,1.0,1.0,1.0,...|\n",
            "|  0.0|[5.0,4.0,4.0,5.0,...|\n",
            "|  0.0|[6.0,8.0,8.0,1.0,...|\n",
            "|  0.0|[4.0,1.0,1.0,3.0,...|\n",
            "|  1.0|[8.0,10.0,10.0,8....|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Realizamos el muestreo de la partición de entrenamiento con el 70% de los datos por clase.\n",
        "train = df.sampleBy(\"label\", fractions={0.0: 0.7, 1.0: 0.7}, seed=42)\n",
        "train.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "A3zkrDIru5y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be98e5a-9592-4e1a-e1ef-e53978b23b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  1.0|[7.0,8.0,7.0,2.0,...|\n",
            "|  0.0|[1.0,1.0,1.0,2.0,...|\n",
            "|  1.0|[5.0,10.0,6.0,1.0...|\n",
            "|  1.0|[10.0,10.0,10.0,6...|\n",
            "|  1.0|[8.0,8.0,9.0,4.0,...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Obtenemos el conjunto de datos que no están en entrenamiento para conformar el conjunto 'test'.\n",
        "test = df.subtract(train)\n",
        "test.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIbdEAgQEeIk"
      },
      "source": [
        "Verificamos que se encuentre estratificado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7Aa6zdazEdpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0890e706-ee2f-4240-fc9e-321a6bf17a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|  314|\n",
            "|  1.0|  189|\n",
            "+-----+-----+\n",
            "\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|   50|\n",
            "|  1.0|   50|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train.groupby(\"label\").count().show()\n",
        "test.groupby(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOfQOei-Gpcb"
      },
      "source": [
        "Con nuestro conjunto de entrada preparado, podemos entrenar nuestro modelo de clasificación. *Apache Spark* dispone de una gran variedad de algoritmos de aprendizaje automático en su módulo **`pyspark.ml`**(disponibles en el siguiente [enlace](https://spark.apache.org/docs/latest/ml-classification-regression.html)). En esta ocasión vamos a crear un modelo de clasificador basado en un árbol de decisión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ueNH27Z5GwKO"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l54Q6zaNHYti"
      },
      "source": [
        "Podemos entrenar el modelo con el método **`fit`**, ingresando el conjunto de datos de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "057itnLUHX9-"
      },
      "outputs": [],
      "source": [
        "model_trained = model.fit(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTiDW-VaHox2"
      },
      "source": [
        "Una vez finalizado el entrenamiento podemos realizar una predicción de los datos con el método **`transform`**, usando como entrada el conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "RkbNAv2QHoAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772ed56c-8e32-4ee7-8d08-ed1691e4590e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+-------------+--------------------+----------+\n",
            "|label|            features|rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+-------------+--------------------+----------+\n",
            "|  1.0|[7.0,8.0,7.0,2.0,...|  [1.0,130.0]|[0.00763358778625...|       1.0|\n",
            "|  0.0|[1.0,1.0,1.0,2.0,...|  [280.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  1.0|[5.0,10.0,6.0,1.0...|    [2.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  1.0|[10.0,10.0,10.0,6...|  [1.0,130.0]|[0.00763358778625...|       1.0|\n",
            "|  1.0|[8.0,8.0,9.0,4.0,...|  [1.0,130.0]|[0.00763358778625...|       1.0|\n",
            "+-----+--------------------+-------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_trained.transform(test)\n",
        "y_pred.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZFqRKlAIFnd"
      },
      "source": [
        "Finalmente, podemos realizar la evaluación del desempeño de nuestros modelos con las [funciones disponibles](https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html) en el módulo **`pyspark.ml.evaluation`**. En este caso, cargamos la función de evaluación del desempeño para clasificación multiclase para acceder a la métrica $F_1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "SF1Bb0nGIIlL"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Xvabvo9SITjC"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "GW957n-SIrHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b701a80-419b-414f-8c31-1f5efee2cffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métrica 'f1': 0.9096\n"
          ]
        }
      ],
      "source": [
        "print(f\"Métrica '{evaluator.getMetricName()}': {evaluator.evaluate(y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuKhUqNlJT7s"
      },
      "source": [
        "## **3.2. Clasificación de texto (datos no estructurados)**\n",
        "---\n",
        "\n",
        "En esta sección vamos a realizar un proceso de clasificación en datos de texto, con el objetivo de ejemplificar el proceso de modelado en datos no estructurados. Para esto, tomaremos el _dataset_  [_Youtube Spam Collection_](https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection) del repositorio de la _UCI_. Este contiene las siguientes características:\n",
        "\n",
        "  | Variable |  Definición  |            Valores |\n",
        "  |---|-----------------|----------------------|\n",
        "  | COMMENT_ID |Identificador del comentario |            Índice |\n",
        "  | AUTHOR | Nombre de usuario del autor del comentario.|               Cadena de texto |\n",
        "  | DATA | Fecha de publicación del comentario.| Cadena de texto |\n",
        "  | CONTENT | Contenido del comentario.| Cadena de texto |\n",
        "  | CLASS | Clase o etiqueta del diagnóstico.       |                  (0 para comentario normal, 1 para _spam_)\n",
        "\n",
        "\n",
        "  Como puede notar, las características originales no disponen de tanta información importante para nuestra tarea, a excepción del texto contenido en el comentario. Es por esta razón que es necesario realizar un proceso de extracción de características del texto para su procesamiento con algoritmos de clasificación. \n",
        "\n",
        "  Empecemos por descargar el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "FJE8mo-cJ4Bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dee09b6-fbe1-4d81-f15d-8763b4def4a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-28 22:03:26--  https://archive.ics.uci.edu/ml/machine-learning-databases/00380/YouTube-Spam-Collection-v1.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 163567 (160K) [application/x-httpd-php]\n",
            "Saving to: ‘YouTube-Spam-Collection-v1.zip’\n",
            "\n",
            "YouTube-Spam-Collec 100%[===================>] 159.73K   817KB/s    in 0.2s    \n",
            "\n",
            "2022-11-28 22:03:27 (817 KB/s) - ‘YouTube-Spam-Collection-v1.zip’ saved [163567/163567]\n",
            "\n",
            "Archive:  YouTube-Spam-Collection-v1.zip\n",
            "  inflating: Youtube01-Psy.csv       \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._Youtube01-Psy.csv  \n",
            "  inflating: Youtube02-KatyPerry.csv  \n",
            "  inflating: __MACOSX/._Youtube02-KatyPerry.csv  \n",
            "  inflating: Youtube03-LMFAO.csv     \n",
            "  inflating: __MACOSX/._Youtube03-LMFAO.csv  \n",
            "  inflating: Youtube04-Eminem.csv    \n",
            "  inflating: __MACOSX/._Youtube04-Eminem.csv  \n",
            "  inflating: Youtube05-Shakira.csv   \n",
            "  inflating: __MACOSX/._Youtube05-Shakira.csv  \n"
          ]
        }
      ],
      "source": [
        "# Descargamos y descomprimimos el conjunto de datos.\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00380/YouTube-Spam-Collection-v1.zip\n",
        "!unzip YouTube-Spam-Collection-v1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1JLAx-TLs6l"
      },
      "source": [
        "Revisamos la colección de archivos en el directorio **`/content`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "XV681naTLGJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1344a46b-5769-446d-f173-3393430d86cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "breast-cancer-wisconsin.data  Youtube03-LMFAO.csv\n",
            "__MACOSX\t\t      Youtube04-Eminem.csv\n",
            "sample_data\t\t      Youtube05-Shakira.csv\n",
            "Youtube01-Psy.csv\t      YouTube-Spam-Collection-v1.zip\n",
            "Youtube02-KatyPerry.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o2L8DPnLz-g"
      },
      "source": [
        "Podemos utilizar cualquiera de los conjuntos individuales de manera aislada para nuestro procesamiento. En esta ocasión cargaremos los datos de los comentarios en los videos de Shakira."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "EDAGemUeL4nS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9dc5638-be83-498b-a700-07f744371492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|          COMMENT_ID|              AUTHOR|                DATE|             CONTENT|CLASS|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|z13lgffb5w3ddx1ul...|          dharma pal|2015-05-29 02:30:...|          Nice song﻿|    0|\n",
            "|z123dbgb0mqjfxbtz...|       Tiza Arellano|2015-05-29 00:14:...|       I love song ﻿|    0|\n",
            "|z12quxxp2vutflkxv...|Prìñçeśś Âliś Łøv...|2015-05-28 21:00:...|       I love song ﻿|    0|\n",
            "|z12icv3ysqvlwth2c...|       Eric Gonzalez|2015-05-28 20:47:...|860,000,000 lets ...|    0|\n",
            "|z133stly3kete3tly...|       Analena López|2015-05-28 17:08:...|shakira is best f...|    0|\n",
            "|z12myn4rltf4ejddv...| jehoiada wellington|2015-05-28 17:06:...|The best world cu...|    0|\n",
            "|z135vzqy1yrjhluew...|    Kara Cuthbertson|2015-05-28 15:46:...|             I love﻿|    0|\n",
            "|z12uujnj2sifvzvav...|       Sudheer Yadav|2015-05-28 10:28:...|SEE SOME MORE SON...|    1|\n",
            "|z13lvh1qnma4d15sy...|           Alex John|2015-05-28 07:44:...|           Awesome ﻿|    0|\n",
            "|z135hlk5grfwjhmym...|     Nirab Valobasha|2015-05-27 21:31:...|   I like shakira..﻿|    0|\n",
            "|z121cvvqftuvuz1ld...|     Chelsea Andrews|2015-05-27 20:43:...|Shakira - Waka Wa...|    0|\n",
            "|z12uf5gatnf1dflws...|          Kevin Sosa|2015-05-27 20:04:...|Why so many disli...|    0|\n",
            "|z13pihfbwlv5hv4ap...|     OldSchool Music|2015-05-27 19:00:...|I don&#39;t think...|    0|\n",
            "|z13utfk5rny3yzqtj...|      Stephen Lister|2015-05-27 16:04:...|          Love song﻿|    0|\n",
            "|z13usjdoivinwzsoy...|    Karolína Hlavatá|2015-05-27 14:41:...|          wery good﻿|    0|\n",
            "|z12bhf4rzpjsvjmcw...|           DubCedSky|2015-05-27 13:51:...|Every time I hear...|    0|\n",
            "|z132i1cj3t2cedajp...|       akita hachiko|2015-05-27 13:07:...|Whose watching th...|    0|\n",
            "|z12aw1ah2m2vh30tb...|        Benjy Growls|2015-05-27 09:27:...|I love this song ...|    0|\n",
            "|z12cydggrzyesrklw...|      monkey moments|2015-05-27 09:24:...|i love this song ...|    0|\n",
            "|z12gddhblwz3cf3wc...|Dr.geetanjali sharma|2015-05-27 09:14:...|      Waka best one﻿|    0|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cargamos el DataFrame a partir del archivo CSV.\n",
        "df_yt = sqlContext.read.csv(\"Youtube05-Shakira.csv\", header=True, inferSchema=True)\n",
        "df_yt.show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QhIhWfvLMg4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfea640b-26a9-45a8-ffbe-531ed1f8f640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- COMMENT_ID: string (nullable = true)\n",
            " |-- AUTHOR: string (nullable = true)\n",
            " |-- DATE: timestamp (nullable = true)\n",
            " |-- CONTENT: string (nullable = true)\n",
            " |-- CLASS: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Revisamos el esquema de la tabla.\n",
        "df_yt.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD9OIc8iMof4"
      },
      "source": [
        "Existen diversos métodos de extracción de características que se escapan del alcance de este material. En particular, _Apache Spark_ dispone de una [amplia colección](https://spark.apache.org/docs/latest/ml-features.html) de algoritmos y funciones para la extracción de características. En esta ocasión consideraremos la extracción basada en el método [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf), discutido en el Módulo 2. \n",
        "\n",
        "Para esto, _tokenizaremos_ o dividiremos en palabras el contenido de los comentarios con el objeto **`pyspark.ml.feature.Tokenizer`**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "MxVaBdi-NtIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19c4cad-b869-4636-a55b-d471aa421af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+\n",
            "|          COMMENT_ID|              AUTHOR|                DATE|             CONTENT|CLASS|               words|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+\n",
            "|z13lgffb5w3ddx1ul...|          dharma pal|2015-05-29 02:30:...|          Nice song﻿|    0|       [nice, song﻿]|\n",
            "|z123dbgb0mqjfxbtz...|       Tiza Arellano|2015-05-29 00:14:...|       I love song ﻿|    0|  [i, love, song, ﻿]|\n",
            "|z12quxxp2vutflkxv...|Prìñçeśś Âliś Łøv...|2015-05-28 21:00:...|       I love song ﻿|    0|  [i, love, song, ﻿]|\n",
            "|z12icv3ysqvlwth2c...|       Eric Gonzalez|2015-05-28 20:47:...|860,000,000 lets ...|    0|[860,000,000, let...|\n",
            "|z133stly3kete3tly...|       Analena López|2015-05-28 17:08:...|shakira is best f...|    0|[shakira, is, bes...|\n",
            "|z12myn4rltf4ejddv...| jehoiada wellington|2015-05-28 17:06:...|The best world cu...|    0|[the, best, world...|\n",
            "|z135vzqy1yrjhluew...|    Kara Cuthbertson|2015-05-28 15:46:...|             I love﻿|    0|          [i, love﻿]|\n",
            "|z12uujnj2sifvzvav...|       Sudheer Yadav|2015-05-28 10:28:...|SEE SOME MORE SON...|    1|[see, some, more,...|\n",
            "|z13lvh1qnma4d15sy...|           Alex John|2015-05-28 07:44:...|           Awesome ﻿|    0|        [awesome, ﻿]|\n",
            "|z135hlk5grfwjhmym...|     Nirab Valobasha|2015-05-27 21:31:...|   I like shakira..﻿|    0|[i, like, shakira...|\n",
            "|z121cvvqftuvuz1ld...|     Chelsea Andrews|2015-05-27 20:43:...|Shakira - Waka Wa...|    0|[shakira, -, waka...|\n",
            "|z12uf5gatnf1dflws...|          Kevin Sosa|2015-05-27 20:04:...|Why so many disli...|    0|[why, so, many, d...|\n",
            "|z13pihfbwlv5hv4ap...|     OldSchool Music|2015-05-27 19:00:...|I don&#39;t think...|    0|[i, don&#39;t, th...|\n",
            "|z13utfk5rny3yzqtj...|      Stephen Lister|2015-05-27 16:04:...|          Love song﻿|    0|       [love, song﻿]|\n",
            "|z13usjdoivinwzsoy...|    Karolína Hlavatá|2015-05-27 14:41:...|          wery good﻿|    0|       [wery, good﻿]|\n",
            "|z12bhf4rzpjsvjmcw...|           DubCedSky|2015-05-27 13:51:...|Every time I hear...|    0|[every, time, i, ...|\n",
            "|z132i1cj3t2cedajp...|       akita hachiko|2015-05-27 13:07:...|Whose watching th...|    0|[whose, watching,...|\n",
            "|z12aw1ah2m2vh30tb...|        Benjy Growls|2015-05-27 09:27:...|I love this song ...|    0|[i, love, this, s...|\n",
            "|z12cydggrzyesrklw...|      monkey moments|2015-05-27 09:24:...|i love this song ...|    0|[i, love, this, s...|\n",
            "|z12gddhblwz3cf3wc...|Dr.geetanjali sharma|2015-05-27 09:14:...|      Waka best one﻿|    0|  [waka, best, one﻿]|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import Tokenizer\n",
        "\n",
        "df_yt = Tokenizer(inputCol=\"CONTENT\", outputCol=\"words\").transform(df_yt)\n",
        "df_yt.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCeA_xEgOtra"
      },
      "source": [
        "Además, excluiremos del análisis los _tokens_ usados para la puntuación como los puntos y las comas con el objeto **`pyspark.ml.feature.StopWordsRemover`**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "H_JUpilcOxGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cbfd4c6-0ea5-4f44-d5e4-af0ff5db8cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+\n",
            "|          COMMENT_ID|              AUTHOR|                DATE|             CONTENT|CLASS|               words|      filtered_words|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+\n",
            "|z13lgffb5w3ddx1ul...|          dharma pal|2015-05-29 02:30:...|          Nice song﻿|    0|       [nice, song﻿]|       [nice, song﻿]|\n",
            "|z123dbgb0mqjfxbtz...|       Tiza Arellano|2015-05-29 00:14:...|       I love song ﻿|    0|  [i, love, song, ﻿]|     [love, song, ﻿]|\n",
            "|z12quxxp2vutflkxv...|Prìñçeśś Âliś Łøv...|2015-05-28 21:00:...|       I love song ﻿|    0|  [i, love, song, ﻿]|     [love, song, ﻿]|\n",
            "|z12icv3ysqvlwth2c...|       Eric Gonzalez|2015-05-28 20:47:...|860,000,000 lets ...|    0|[860,000,000, let...|[860,000,000, let...|\n",
            "|z133stly3kete3tly...|       Analena López|2015-05-28 17:08:...|shakira is best f...|    0|[shakira, is, bes...|[shakira, best, w...|\n",
            "|z12myn4rltf4ejddv...| jehoiada wellington|2015-05-28 17:06:...|The best world cu...|    0|[the, best, world...|[best, world, cup...|\n",
            "|z135vzqy1yrjhluew...|    Kara Cuthbertson|2015-05-28 15:46:...|             I love﻿|    0|          [i, love﻿]|             [love﻿]|\n",
            "|z12uujnj2sifvzvav...|       Sudheer Yadav|2015-05-28 10:28:...|SEE SOME MORE SON...|    1|[see, some, more,...|[see, song, open,...|\n",
            "|z13lvh1qnma4d15sy...|           Alex John|2015-05-28 07:44:...|           Awesome ﻿|    0|        [awesome, ﻿]|        [awesome, ﻿]|\n",
            "|z135hlk5grfwjhmym...|     Nirab Valobasha|2015-05-27 21:31:...|   I like shakira..﻿|    0|[i, like, shakira...|  [like, shakira..﻿]|\n",
            "|z121cvvqftuvuz1ld...|     Chelsea Andrews|2015-05-27 20:43:...|Shakira - Waka Wa...|    0|[shakira, -, waka...|[shakira, -, waka...|\n",
            "|z12uf5gatnf1dflws...|          Kevin Sosa|2015-05-27 20:04:...|Why so many disli...|    0|[why, so, many, d...|[many, disliked??...|\n",
            "|z13pihfbwlv5hv4ap...|     OldSchool Music|2015-05-27 19:00:...|I don&#39;t think...|    0|[i, don&#39;t, th...|[don&#39;t, think...|\n",
            "|z13utfk5rny3yzqtj...|      Stephen Lister|2015-05-27 16:04:...|          Love song﻿|    0|       [love, song﻿]|       [love, song﻿]|\n",
            "|z13usjdoivinwzsoy...|    Karolína Hlavatá|2015-05-27 14:41:...|          wery good﻿|    0|       [wery, good﻿]|       [wery, good﻿]|\n",
            "|z12bhf4rzpjsvjmcw...|           DubCedSky|2015-05-27 13:51:...|Every time I hear...|    0|[every, time, i, ...|[every, time, hea...|\n",
            "|z132i1cj3t2cedajp...|       akita hachiko|2015-05-27 13:07:...|Whose watching th...|    0|[whose, watching,...|[whose, watching,...|\n",
            "|z12aw1ah2m2vh30tb...|        Benjy Growls|2015-05-27 09:27:...|I love this song ...|    0|[i, love, this, s...|[love, song, much...|\n",
            "|z12cydggrzyesrklw...|      monkey moments|2015-05-27 09:24:...|i love this song ...|    0|[i, love, this, s...|[love, song, thum...|\n",
            "|z12gddhblwz3cf3wc...|Dr.geetanjali sharma|2015-05-27 09:14:...|      Waka best one﻿|    0|  [waka, best, one﻿]|  [waka, best, one﻿]|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n",
        "\n",
        "df_yt = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\").transform(df_yt)\n",
        "df_yt.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q7bqisKQwNK"
      },
      "source": [
        "Ahora, utilizaremos la columna con los _tokens_ filtrados para realizar la extracción con _TF-IDF_. Para esto, deberemos realizar las transformaciones el objeto **`pyspark.ml.feature.HashingTF`** y **`pyspark.ml.feature.IDF`** de manera secuencial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "1F8umba4UWTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e15425-07ba-413c-e8c9-5715d803a34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
            "|          COMMENT_ID|              AUTHOR|                DATE|             CONTENT|CLASS|               words|      filtered_words|              raw_tf|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
            "|z13lgffb5w3ddx1ul...|          dharma pal|2015-05-29 02:30:...|          Nice song﻿|    0|       [nice, song﻿]|       [nice, song﻿]|(20,[10,12],[1.0,...|\n",
            "|z123dbgb0mqjfxbtz...|       Tiza Arellano|2015-05-29 00:14:...|       I love song ﻿|    0|  [i, love, song, ﻿]|     [love, song, ﻿]|(20,[0,10,15],[1....|\n",
            "|z12quxxp2vutflkxv...|Prìñçeśś Âliś Łøv...|2015-05-28 21:00:...|       I love song ﻿|    0|  [i, love, song, ﻿]|     [love, song, ﻿]|(20,[0,10,15],[1....|\n",
            "|z12icv3ysqvlwth2c...|       Eric Gonzalez|2015-05-28 20:47:...|860,000,000 lets ...|    0|[860,000,000, let...|[860,000,000, let...|(20,[3,5,6,7,13,1...|\n",
            "|z133stly3kete3tly...|       Analena López|2015-05-28 17:08:...|shakira is best f...|    0|[shakira, is, bes...|[shakira, best, w...|(20,[3,16,18],[1....|\n",
            "|z12myn4rltf4ejddv...| jehoiada wellington|2015-05-28 17:06:...|The best world cu...|    0|[the, best, world...|[best, world, cup...|(20,[0,3,10,19],[...|\n",
            "|z135vzqy1yrjhluew...|    Kara Cuthbertson|2015-05-28 15:46:...|             I love﻿|    0|          [i, love﻿]|             [love﻿]|     (20,[11],[1.0])|\n",
            "|z12uujnj2sifvzvav...|       Sudheer Yadav|2015-05-28 10:28:...|SEE SOME MORE SON...|    1|[see, some, more,...|[see, song, open,...|(20,[3,6,10,14,15...|\n",
            "|z13lvh1qnma4d15sy...|           Alex John|2015-05-28 07:44:...|           Awesome ﻿|    0|        [awesome, ﻿]|        [awesome, ﻿]|(20,[5,15],[1.0,1...|\n",
            "|z135hlk5grfwjhmym...|     Nirab Valobasha|2015-05-27 21:31:...|   I like shakira..﻿|    0|[i, like, shakira...|  [like, shakira..﻿]|(20,[10,12],[1.0,...|\n",
            "|z121cvvqftuvuz1ld...|     Chelsea Andrews|2015-05-27 20:43:...|Shakira - Waka Wa...|    0|[shakira, -, waka...|[shakira, -, waka...|(20,[3,9,12,18,19...|\n",
            "|z12uf5gatnf1dflws...|          Kevin Sosa|2015-05-27 20:04:...|Why so many disli...|    0|[why, so, many, d...|[many, disliked??...|(20,[8,15],[1.0,1...|\n",
            "|z13pihfbwlv5hv4ap...|     OldSchool Music|2015-05-27 19:00:...|I don&#39;t think...|    0|[i, don&#39;t, th...|[don&#39;t, think...|(20,[3,6,10,11,14...|\n",
            "|z13utfk5rny3yzqtj...|      Stephen Lister|2015-05-27 16:04:...|          Love song﻿|    0|       [love, song﻿]|       [love, song﻿]|(20,[0,12],[1.0,1...|\n",
            "|z13usjdoivinwzsoy...|    Karolína Hlavatá|2015-05-27 14:41:...|          wery good﻿|    0|       [wery, good﻿]|       [wery, good﻿]|(20,[6,9],[1.0,1.0])|\n",
            "|z12bhf4rzpjsvjmcw...|           DubCedSky|2015-05-27 13:51:...|Every time I hear...|    0|[every, time, i, ...|[every, time, hea...|(20,[1,2,4,8,9,15...|\n",
            "|z132i1cj3t2cedajp...|       akita hachiko|2015-05-27 13:07:...|Whose watching th...|    0|[whose, watching,...|[whose, watching,...|(20,[11,12,15,19]...|\n",
            "|z12aw1ah2m2vh30tb...|        Benjy Growls|2015-05-27 09:27:...|I love this song ...|    0|[i, love, this, s...|[love, song, much...|(20,[0,3,4,5,10,1...|\n",
            "|z12cydggrzyesrklw...|      monkey moments|2015-05-27 09:24:...|i love this song ...|    0|[i, love, this, s...|[love, song, thum...|(20,[0,3,10],[1.0...|\n",
            "|z12gddhblwz3cf3wc...|Dr.geetanjali sharma|2015-05-27 09:14:...|      Waka best one﻿|    0|  [waka, best, one﻿]|  [waka, best, one﻿]|(20,[2,3,19],[1.0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TF - Frecuencia de términos.\n",
        "from pyspark.ml.feature import HashingTF\n",
        "\n",
        "df_yt = (HashingTF(inputCol=\"filtered_words\", \n",
        "                   outputCol=\"raw_tf\", \n",
        "                   numFeatures=20)\n",
        "        .transform(df_yt))\n",
        "\n",
        "df_yt.show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "n57Su89E6Ljr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18c44c8-0fe2-4ee1-8f76-4456d9aed2c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "|          COMMENT_ID|              AUTHOR|                DATE|             CONTENT|CLASS|               words|      filtered_words|              raw_tf|               tfidf|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "|z13lgffb5w3ddx1ul...|          dharma pal|2015-05-29 02:30:...|          Nice song﻿|    0|       [nice, song﻿]|       [nice, song﻿]|(20,[10,12],[1.0,...|(20,[10,12],[0.89...|\n",
            "|z123dbgb0mqjfxbtz...|       Tiza Arellano|2015-05-29 00:14:...|       I love song ﻿|    0|  [i, love, song, ﻿]|     [love, song, ﻿]|(20,[0,10,15],[1....|(20,[0,10,15],[0....|\n",
            "|z12quxxp2vutflkxv...|Prìñçeśś Âliś Łøv...|2015-05-28 21:00:...|       I love song ﻿|    0|  [i, love, song, ﻿]|     [love, song, ﻿]|(20,[0,10,15],[1....|(20,[0,10,15],[0....|\n",
            "|z12icv3ysqvlwth2c...|       Eric Gonzalez|2015-05-28 20:47:...|860,000,000 lets ...|    0|[860,000,000, let...|[860,000,000, let...|(20,[3,5,6,7,13,1...|(20,[3,5,6,7,13,1...|\n",
            "|z133stly3kete3tly...|       Analena López|2015-05-28 17:08:...|shakira is best f...|    0|[shakira, is, bes...|[shakira, best, w...|(20,[3,16,18],[1....|(20,[3,16,18],[1....|\n",
            "|z12myn4rltf4ejddv...| jehoiada wellington|2015-05-28 17:06:...|The best world cu...|    0|[the, best, world...|[best, world, cup...|(20,[0,3,10,19],[...|(20,[0,3,10,19],[...|\n",
            "|z135vzqy1yrjhluew...|    Kara Cuthbertson|2015-05-28 15:46:...|             I love﻿|    0|          [i, love﻿]|             [love﻿]|     (20,[11],[1.0])|(20,[11],[1.37290...|\n",
            "|z12uujnj2sifvzvav...|       Sudheer Yadav|2015-05-28 10:28:...|SEE SOME MORE SON...|    1|[see, some, more,...|[see, song, open,...|(20,[3,6,10,14,15...|(20,[3,6,10,14,15...|\n",
            "|z13lvh1qnma4d15sy...|           Alex John|2015-05-28 07:44:...|           Awesome ﻿|    0|        [awesome, ﻿]|        [awesome, ﻿]|(20,[5,15],[1.0,1...|(20,[5,15],[1.180...|\n",
            "|z135hlk5grfwjhmym...|     Nirab Valobasha|2015-05-27 21:31:...|   I like shakira..﻿|    0|[i, like, shakira...|  [like, shakira..﻿]|(20,[10,12],[1.0,...|(20,[10,12],[0.89...|\n",
            "|z121cvvqftuvuz1ld...|     Chelsea Andrews|2015-05-27 20:43:...|Shakira - Waka Wa...|    0|[shakira, -, waka...|[shakira, -, waka...|(20,[3,9,12,18,19...|(20,[3,9,12,18,19...|\n",
            "|z12uf5gatnf1dflws...|          Kevin Sosa|2015-05-27 20:04:...|Why so many disli...|    0|[why, so, many, d...|[many, disliked??...|(20,[8,15],[1.0,1...|(20,[8,15],[1.137...|\n",
            "|z13pihfbwlv5hv4ap...|     OldSchool Music|2015-05-27 19:00:...|I don&#39;t think...|    0|[i, don&#39;t, th...|[don&#39;t, think...|(20,[3,6,10,11,14...|(20,[3,6,10,11,14...|\n",
            "|z13utfk5rny3yzqtj...|      Stephen Lister|2015-05-27 16:04:...|          Love song﻿|    0|       [love, song﻿]|       [love, song﻿]|(20,[0,12],[1.0,1...|(20,[0,12],[0.866...|\n",
            "|z13usjdoivinwzsoy...|    Karolína Hlavatá|2015-05-27 14:41:...|          wery good﻿|    0|       [wery, good﻿]|       [wery, good﻿]|(20,[6,9],[1.0,1.0])|(20,[6,9],[1.3210...|\n",
            "|z12bhf4rzpjsvjmcw...|           DubCedSky|2015-05-27 13:51:...|Every time I hear...|    0|[every, time, i, ...|[every, time, hea...|(20,[1,2,4,8,9,15...|(20,[1,2,4,8,9,15...|\n",
            "|z132i1cj3t2cedajp...|       akita hachiko|2015-05-27 13:07:...|Whose watching th...|    0|[whose, watching,...|[whose, watching,...|(20,[11,12,15,19]...|(20,[11,12,15,19]...|\n",
            "|z12aw1ah2m2vh30tb...|        Benjy Growls|2015-05-27 09:27:...|I love this song ...|    0|[i, love, this, s...|[love, song, much...|(20,[0,3,4,5,10,1...|(20,[0,3,4,5,10,1...|\n",
            "|z12cydggrzyesrklw...|      monkey moments|2015-05-27 09:24:...|i love this song ...|    0|[i, love, this, s...|[love, song, thum...|(20,[0,3,10],[1.0...|(20,[0,3,10],[0.8...|\n",
            "|z12gddhblwz3cf3wc...|Dr.geetanjali sharma|2015-05-27 09:14:...|      Waka best one﻿|    0|  [waka, best, one﻿]|  [waka, best, one﻿]|(20,[2,3,19],[1.0...|(20,[2,3,19],[0.9...|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# IDF - Frecuencia inversa de documento.\n",
        "from pyspark.ml.feature import IDF\n",
        "\n",
        "df_yt = IDF(inputCol=\"raw_tf\", outputCol=\"tfidf\").fit(df_yt).transform(df_yt)\n",
        "df_yt.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n79g6MYGop7w"
      },
      "source": [
        "Finalmente realizaremos un modelo de clasificación de la misma manera que en la sección anterior con las características extraídas. Antes de proceder, realizamos un conteo de las clases almacenadas en el _dataset_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "B4ngmcgtjVHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd3c09e-241a-4f3c-e542-ad34541a2f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|               CLASS|count|\n",
            "+--------------------+-----+\n",
            "|                   0|  196|\n",
            "| Help Rand Protec...|    1|\n",
            "|                   1|  173|\n",
            "+--------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_yt.groupBy(\"CLASS\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ipsi83Nj18j"
      },
      "source": [
        "Observe que debemos hacer limpieza a la etiqueta  **`CLASS`** y eliminar el dato atípico. Podemos usar el método **`isin`** para limitar los valores a una colección predefinida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "KKrrKWPUkAYC"
      },
      "outputs": [],
      "source": [
        "# Filtramos únicamente los valores '0' y '1'.\n",
        "df_yt = df_yt.where(df_yt[\"CLASS\"].isin([\"0\", \"1\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyC1O7bNo_6t"
      },
      "source": [
        "Ahora, transformemos la columna de la clase a **`label`** con el objeto **`StringIndexer`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Qg6TAq_Kkr-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33001810-bada-4530-b429-b5793ecd1d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|          COMMENT_ID|              AUTHOR|                DATE|             CONTENT|CLASS|               words|      filtered_words|              raw_tf|               tfidf|label|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "|z13lgffb5w3ddx1ul...|          dharma pal|2015-05-29 02:30:...|          Nice song﻿|    0|       [nice, song﻿]|       [nice, song﻿]|(20,[10,12],[1.0,...|(20,[10,12],[0.89...|  0.0|\n",
            "|z123dbgb0mqjfxbtz...|       Tiza Arellano|2015-05-29 00:14:...|       I love song ﻿|    0|  [i, love, song, ﻿]|     [love, song, ﻿]|(20,[0,10,15],[1....|(20,[0,10,15],[0....|  0.0|\n",
            "|z12quxxp2vutflkxv...|Prìñçeśś Âliś Łøv...|2015-05-28 21:00:...|       I love song ﻿|    0|  [i, love, song, ﻿]|     [love, song, ﻿]|(20,[0,10,15],[1....|(20,[0,10,15],[0....|  0.0|\n",
            "|z12icv3ysqvlwth2c...|       Eric Gonzalez|2015-05-28 20:47:...|860,000,000 lets ...|    0|[860,000,000, let...|[860,000,000, let...|(20,[3,5,6,7,13,1...|(20,[3,5,6,7,13,1...|  0.0|\n",
            "+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "df_yt = StringIndexer(inputCol=\"CLASS\", outputCol=\"label\").fit(df_yt).transform(df_yt)\n",
        "df_yt.show(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCYWBY5npLZ4"
      },
      "source": [
        "Ahora, realizaremos la partición estratificada del conjunto de datos en entrenamiento (**`train`**) y pruebas (**`test`**), con el $70\\%$ de los datos para entrenamiento y el $30\\%$ para pruebas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "buGKrcK4ktMg"
      },
      "outputs": [],
      "source": [
        "# Realizamos la particion de los datos.\n",
        "train = df_yt.sampleBy(\"label\", fractions={0.0: 0.7, 1.0: 0.7}, seed=123)\n",
        "test = df_yt.subtract(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcQKCBqBmiMW"
      },
      "source": [
        "Verificamos que se encuentran estratificados ambos conjuntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Up0x1Ep7miMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8e1ab8-ca38-4256-82f5-812064361ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|  137|\n",
            "|  1.0|  123|\n",
            "+-----+-----+\n",
            "\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|   58|\n",
            "|  1.0|   50|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train.groupby(\"label\").count().show()\n",
        "test.groupBy(\"label\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M1WIW49miMy"
      },
      "source": [
        "Nos quedamos únicamente con las *features* y los *labels* tanto en *train* como en *test*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "vfPODoBAmiMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5086a0f1-ef35-48c4-d582-98ff91a45e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|               tfidf|\n",
            "+-----+--------------------+\n",
            "|  0.0|(20,[10,12],[0.89...|\n",
            "|  0.0|(20,[0,10,15],[0....|\n",
            "|  0.0|(20,[3,5,6,7,13,1...|\n",
            "|  0.0|(20,[3,16,18],[1....|\n",
            "+-----+--------------------+\n",
            "only showing top 4 rows\n",
            "\n",
            "+-----+--------------------+\n",
            "|label|               tfidf|\n",
            "+-----+--------------------+\n",
            "|  1.0|(20,[1,6,14,15],[...|\n",
            "|  0.0|(20,[2,12,15,19],...|\n",
            "|  0.0|(20,[2,3,5,7,8,9,...|\n",
            "|  0.0|(20,[9],[1.271811...|\n",
            "+-----+--------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train = train.select(\"label\", \"tfidf\")\n",
        "train.show(4)\n",
        "test = test.select(\"label\", \"tfidf\")\n",
        "test.show(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE6LGywLmiM4"
      },
      "source": [
        "Crearemos un modelo SVC lineal con los siguientes hiperparámetros. Es importante indicarle la columna de las _features_ a usar con el parámetro **`featureCol`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "nRcGV4-qmiM6"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "model = LinearSVC(maxIter=100, regParam=0.01, featuresCol=\"tfidf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9bOmSr-miM-"
      },
      "source": [
        "Entrenamos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "9USXxgsAmiM_"
      },
      "outputs": [],
      "source": [
        "# Entrenamos el modelo SVC.\n",
        "model_trained = model.fit(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s62JGG1dmiNF"
      },
      "source": [
        "Predecimos en _test_ utilizando el modelo entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "D24QqFBJmiNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "768faa73-3d50-40c3-fbf4-43c96fc56940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------------------+----------+\n",
            "|label|               tfidf|       rawPrediction|prediction|\n",
            "+-----+--------------------+--------------------+----------+\n",
            "|  1.0|(20,[1,6,14,15],[...|[-0.8656460695914...|       1.0|\n",
            "|  0.0|(20,[2,12,15,19],...|[0.61905995268425...|       0.0|\n",
            "|  0.0|(20,[2,3,5,7,8,9,...|[-6.2582659602724...|       1.0|\n",
            "|  0.0|(20,[9],[1.271811...|[1.04972755522370...|       0.0|\n",
            "+-----+--------------------+--------------------+----------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Realizamos una predicción.\n",
        "y_pred = model_trained.transform(test)\n",
        "y_pred.show(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wxme3QtmiNL"
      },
      "source": [
        "Evaluamos el modelo. Tenga en cuenta que en este caso usaremos una medida de evaluación de problemas de clasificación binarios más apropiada como lo es el área bajo la curva ROC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "91iXaT5VmiNR"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import  BinaryClassificationEvaluator\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "dj8AFP8smiNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab83d28-0391-42bc-a37e-11d4a7717ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métrica 'areaUnderROC': 0.9099999999999996\n"
          ]
        }
      ],
      "source": [
        "print(f\"Métrica '{evaluator.getMetricName()}': {evaluator.evaluate(y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r51cD1GhemqW"
      },
      "source": [
        "## **Referencias y recursos adicionales**\n",
        "---\n",
        "\n",
        "* [_Apache Spark_ - Documentación _SparkSQL_ y DataFrames](https://spark.apache.org/docs/latest/sql-programming-guide.html)\n",
        "* [_Apache Spark_ - Documentación _MLLib_](https://spark.apache.org/docs/latest/ml-guide.html)\n",
        "* [Guru99 - PySpark Tutorial for Beginners](https://www.guru99.com/pyspark-tutorial.html)\n",
        "* [mlcourse.ai - _Open Machine Learning Course_](https://mlcourse.ai)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4VavQ3wgMGo"
      },
      "source": [
        "## **Créditos**\n",
        "---\n",
        "\n",
        "* **Profesor:** [Jorge E. Camargo, PhD](https://dis.unal.edu.co/~jecamargom/)\n",
        "* **Asistentes docentes:**\n",
        "  - Leonardo Avendaño Rocha\n",
        "  - Miguel Ángel Ortiz Marin\n",
        "  - Alberto Nicolai Romero Martínez  \n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6oUIVZHXxQPE",
        "r51cD1GhemqW",
        "z4VavQ3wgMGo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}